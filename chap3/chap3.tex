\chapter{提案手法}
\thispagestyle{empty}
\label{chap3}
\minitoc

\newpage

\section{はじめに}
本章では，本研究で行う提案手法や使用するロボットについて述べる．3.2節では提案手法について述べる．

\section{提案手法}
本研究の目的は、Q学習を基礎とした強化学習アルゴリズムと、知識選択型転移強化学習メカニズムであるSAP-netを組み合わせた新しいアプローチを開発し、その有効性を検証することにある。この目的を達成するために、高度な物理演算を実現するシミュレータWebotsを使用し、ロボットが複雑な障害物環境下での行動策を効率的に学習できるかどうかを検証する．
\subsection{Q学習による強化学習実験）}
初めに複数の配置パターンの障害物配置が含まれる環境下でQ学習による強化学習実験を行う．
\subsection{SAP-netの活用}
SAP-netはロボットの初期座標を基準に障害物までの角度と距離を保存させる．この情報はロボットが環境を理解し，障害物を正確に把握するための基盤となる．次に強化学習から得た行動価値関数の情報を取得し，それらの類似度を計算する．類似度計算は異なる状況における最適な行動の一貫性を確認する重要なステップである．そして計算された類似度情報を基にネットワークを構築する．このネットワークは活性化拡散モデルとして機能し，異なる行動価値関数を統合し，環境への柔軟な対応を可能にする．そして構築されたネットワークは知識を選択し，動的な状況において障害物回避の戦略を提供する．これによりロボットは瞬時の判断により，適切な知識を活用して効果的な障害物回避を実現する．
\section{物理演算シミュレーション}
強化学習は試行錯誤的に行動を何千と繰り返して学習するため，実環境でやると時間がかかってしまう．また実機で使用するロボットが破損する恐れがある．そこでWebotsという物理演算シミュレーションを使用する．[Webots1998]．Webotsの操作画面をFig．\ref{webots_stage}に示す．Webotsを使用することで，シミュレーション内のロボットが強化学習を行っていくため，実環境で行うよりも安全に効率よく学習することが可能である．使用するロボットモデルをFig.\ref{model}に示す．また障害物の認識はLIDARを使用する．

\begin{figure}[h]
	\centering
	\includegraphics[width=60mm]{./chap2/chap2_fig/webots_stage}
	\caption{Webotsの操作画面}
	\label{webots_stage}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=40mm]{./chap2/chap2_fig/model}
	\caption{シミュレーションで用いるロボットモデル}
	\label{model}
\end{figure}

\subsection{シミュレーションから現実への適応}

\section{おわりに}




\clearpage
\newpage



